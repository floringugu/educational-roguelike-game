# ü§ñ Modelos de IA Disponibles - Gu√≠a de Selecci√≥n

## üìä Comparaci√≥n de Modelos

| Modelo | Disponibilidad | Velocidad | Calidad | Compatibilidad | Recomendado |
|--------|----------------|-----------|---------|----------------|-------------|
| **mistralai/Mistral-7B-Instruct-v0.2** | ‚úÖ Siempre | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ chat API | ‚úÖ **S√ç** |
| **microsoft/Phi-3-mini-4k-instruct** | ‚ö†Ô∏è API de pago | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ text-gen | ‚ö†Ô∏è Avanzado |
| **HuggingFaceH4/zephyr-7b-beta** | ‚úÖ Siempre | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö†Ô∏è chat only | ‚ö†Ô∏è Avanzado |
| **mistralai/Mixtral-8x7B-Instruct-v0.1** | ‚ö†Ô∏è Variable | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ text-gen | ‚ö†Ô∏è A veces |

---

## üéØ Modelo Recomendado: Mistral-7B-Instruct-v0.2

### ‚úÖ Ventajas

- **Siempre disponible**: Funciona 24/7 en la API serverless gratuita de Hugging Face
- **Muy r√°pido**: Genera preguntas en 4-6 segundos
- **Excelente calidad**: De los creadores de Mixtral, optimizado para instrucciones
- **100% Gratis**: Funciona perfectamente con la API gratuita
- **M√°xima compatibilidad**: Usa chat API (el c√≥digo lo maneja autom√°ticamente)
- **Confiable**: Probado y verificado que funciona con cuentas gratuitas
- **Sin restricciones**: No requiere tier de pago

**Nota importante**: Mistral-7B-Instruct usa la **chat API** (conversational), no text-generation. El c√≥digo hace esto autom√°ticamente, no necesitas cambiar nada.

### üìù Configuraci√≥n

Ya est√° configurado por defecto en tu `.env`:

```bash
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
```

---

## üîÑ Modelos Alternativos

### 1. Phi-3-mini-4k-instruct (Muy R√°pido, pero...)

‚ö†Ô∏è **Puede requerir tier de pago de Hugging Face**

```bash
HUGGINGFACE_MODEL=microsoft/Phi-3-mini-4k-instruct
```

**Caracter√≠sticas:**
- ‚ö° El m√°s r√°pido (~2-3 segundos)
- ‚≠ê Excelente calidad
- ‚ö†Ô∏è **Requiere tier de pago de HuggingFace** (error 403 con API gratuita)
- ‚úÖ Si tienes tier de pago, funciona perfectamente
- üîß Creado por Microsoft

**Nota:** Si obtienes error 403, usa Mistral-7B en su lugar.

---

### 2. Zephyr-7b-beta (Avanzado)

‚ö†Ô∏è **Requiere API de chat (el c√≥digo lo maneja autom√°ticamente)**

```bash
HUGGINGFACE_MODEL=HuggingFaceH4/zephyr-7b-beta
```

**Caracter√≠sticas:**
- ‚≠ê Excelente calidad
- ‚úÖ Siempre disponible
- üîß Usa chat API en lugar de text-generation
- ‚ö° R√°pido
- ‚ö†Ô∏è El c√≥digo hace fallback autom√°tico si falla

---

### 3. Mixtral-8x7B (M√°xima Calidad, pero...)

‚ö†Ô∏è **Solo usar si funciona en tu cuenta**

```bash
HUGGINGFACE_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1
```

**Caracter√≠sticas:**
- ‚≠ê M√°xima calidad
- ‚ö†Ô∏è **NO siempre disponible** en API serverless gratuita
- üêå M√°s lento (modelo muy grande: 47B par√°metros)
- ‚ùå Puede dar error "modelo no disponible"

**Por qu√© no est√° siempre disponible:**
- Es un modelo muy grande (pesa ~90GB)
- Hugging Face lo ejecuta en GPUs especiales
- Puede estar "durmiendo" si no se usa frecuentemente
- Tarda en "despertar" (loading state)

---

## üîß ¬øC√≥mo Cambiar de Modelo?

1. Abre el archivo `.env` en la ra√≠z del proyecto
2. Encuentra la l√≠nea `HUGGINGFACE_MODEL=...`
3. Reempl√°zala con el modelo que quieras
4. Guarda el archivo
5. Reinicia la aplicaci√≥n (`python app.py`)

---

## üí° Recomendaciones

### Para API gratuita (RECOMENDADO):
```bash
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
```

### Si tienes tier de pago de HuggingFace:
```bash
HUGGINGFACE_MODEL=microsoft/Phi-3-mini-4k-instruct
```

### Si eres usuario avanzado:
```bash
HUGGINGFACE_MODEL=HuggingFaceH4/zephyr-7b-beta
```

### Si Mixtral funciona para ti:
```bash
HUGGINGFACE_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1
```

---

## üêõ Troubleshooting

### Error: "Model not currently available"

**Causa:** El modelo est√° en estado "loading" o no disponible en API serverless.

**Soluci√≥n:**
1. Cambia a Zephyr-7b-beta o Phi-3-mini
2. Estos modelos siempre est√°n disponibles

### Error: "Model is loading"

**Causa:** El modelo grande est√° "despertando".

**Soluci√≥n:**
- Espera 30-60 segundos y vuelve a intentar
- O cambia a un modelo m√°s ligero

### Preguntas de baja calidad

**Soluci√≥n:**
1. Prueba con Mistral-7B o Zephyr
2. Ambos generan excelentes preguntas educativas

---

## üìä Rendimiento Comparativo

### Tiempo de generaci√≥n (10 preguntas):

| Modelo | Tiempo Promedio | Disponibilidad |
|--------|-----------------|----------------|
| Mistral-7B | ~4-6 segundos | ‚úÖ API gratuita |
| Phi-3-mini | ~2-3 segundos ‚ö° | ‚ö†Ô∏è Requiere tier de pago |
| Zephyr-7b | ~4-5 segundos | ‚úÖ API gratuita |
| Mixtral-8x7B | ~15 segundos | ‚ö†Ô∏è Variable |

### Calidad de preguntas:

Todos los modelos recomendados generan preguntas de alta calidad para prop√≥sitos educativos. Las diferencias son m√≠nimas en la pr√°ctica.

---

## ‚úÖ Conclusi√≥n

**Usa Mistral-7B-Instruct-v0.2** (configuraci√≥n actual) - Es la mejor opci√≥n para API gratuita:
- ‚úÖ Funciona perfecto con API gratuita de Hugging Face
- ‚úÖ Disponibilidad garantizada 24/7
- ‚úÖ Calidad excelente para preguntas educativas
- ‚úÖ 100% gratis sin restricciones
- ‚úÖ R√°pido (4-6 segundos)
- ‚úÖ M√°xima compatibilidad (text-generation API)
- ‚úÖ De los creadores de Mixtral, muy confiable

**Solo cambia si:**
- Tienes tier de pago ‚Üí Phi-3-mini-4k-instruct (m√°s r√°pido)
- Eres usuario avanzado ‚Üí Zephyr-7b-beta (usa chat API)
- Mixtral funciona para ti ‚Üí Mixtral-8x7B-Instruct-v0.1

---

**Fecha:** 2025-11-18
**Versi√≥n:** 1.0
