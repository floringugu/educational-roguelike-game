# ğŸ¤– Modelos de IA Disponibles - GuÃ­a de SelecciÃ³n

## ğŸ“Š ComparaciÃ³n de Modelos

| Modelo | Disponibilidad | Velocidad | Calidad | Recomendado |
|--------|----------------|-----------|---------|-------------|
| **HuggingFaceH4/zephyr-7b-beta** | âœ… Siempre | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | âœ… SÃ |
| **microsoft/Phi-3-mini-4k-instruct** | âœ… Siempre | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­ | âœ… SÃ |
| **mistralai/Mistral-7B-Instruct-v0.2** | âœ… Siempre | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | âœ… SÃ |
| **mistralai/Mixtral-8x7B-Instruct-v0.1** | âš ï¸ Variable | âš¡âš¡âš¡ | â­â­â­â­â­ | âš ï¸ A veces |

---

## ğŸ¯ Modelo Recomendado: Zephyr-7b-beta

### âœ… Ventajas

- **Siempre disponible**: Funciona 24/7 en la API serverless de Hugging Face
- **Muy rÃ¡pido**: Genera preguntas en 2-5 segundos
- **Excelente calidad**: Optimizado para seguir instrucciones
- **Gratis**: 100% gratuito con tu API key
- **Confiable**: No falla por "modelo no disponible"

### ğŸ“ ConfiguraciÃ³n

Ya estÃ¡ configurado por defecto en tu `.env`:

```bash
HUGGINGFACE_MODEL=HuggingFaceH4/zephyr-7b-beta
```

---

## ğŸ”„ Modelos Alternativos

### 1. Microsoft Phi-3 Mini (MÃ¡s RÃ¡pido)

Si necesitas mÃ¡xima velocidad:

```bash
HUGGINGFACE_MODEL=microsoft/Phi-3-mini-4k-instruct
```

**CaracterÃ­sticas:**
- âš¡ El mÃ¡s rÃ¡pido de todos
- ğŸ¯ Muy eficiente
- âœ… Siempre disponible
- ğŸ“ Calidad muy buena

---

### 2. Mistral-7B (Balance)

Si prefieres Mistral pero mÃ¡s ligero que Mixtral:

```bash
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
```

**CaracterÃ­sticas:**
- ğŸ¯ Excelente balance calidad/velocidad
- âœ… Siempre disponible
- ğŸ“ Muy buena calidad de respuestas
- ğŸ”§ De los creadores de Mixtral

---

### 3. Mixtral-8x7B (Mayor Calidad, pero...)

âš ï¸ **Solo usar si funciona en tu cuenta**

```bash
HUGGINGFACE_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1
```

**CaracterÃ­sticas:**
- â­ MÃ¡xima calidad
- âš ï¸ **NO siempre disponible** en API serverless gratuita
- ğŸŒ MÃ¡s lento (modelo muy grande: 47B parÃ¡metros)
- âŒ Puede dar error "modelo no disponible"

**Por quÃ© no estÃ¡ siempre disponible:**
- Es un modelo muy grande (pesa ~90GB)
- Hugging Face lo ejecuta en GPUs especiales
- Puede estar "durmiendo" si no se usa frecuentemente
- Tarda en "despertar" (loading state)

---

## ğŸ”§ Â¿CÃ³mo Cambiar de Modelo?

1. Abre el archivo `.env` en la raÃ­z del proyecto
2. Encuentra la lÃ­nea `HUGGINGFACE_MODEL=...`
3. ReemplÃ¡zala con el modelo que quieras
4. Guarda el archivo
5. Reinicia la aplicaciÃ³n (`python app.py`)

---

## ğŸ’¡ Recomendaciones

### Para uso general:
```bash
HUGGINGFACE_MODEL=HuggingFaceH4/zephyr-7b-beta
```

### Si necesitas velocidad mÃ¡xima:
```bash
HUGGINGFACE_MODEL=microsoft/Phi-3-mini-4k-instruct
```

### Si Mixtral funciona para ti:
```bash
HUGGINGFACE_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1
```

---

## ğŸ› Troubleshooting

### Error: "Model not currently available"

**Causa:** El modelo estÃ¡ en estado "loading" o no disponible en API serverless.

**SoluciÃ³n:**
1. Cambia a Zephyr-7b-beta o Phi-3-mini
2. Estos modelos siempre estÃ¡n disponibles

### Error: "Model is loading"

**Causa:** El modelo grande estÃ¡ "despertando".

**SoluciÃ³n:**
- Espera 30-60 segundos y vuelve a intentar
- O cambia a un modelo mÃ¡s ligero

### Preguntas de baja calidad

**SoluciÃ³n:**
1. Prueba con Mistral-7B o Zephyr
2. Ambos generan excelentes preguntas educativas

---

## ğŸ“Š Rendimiento Comparativo

### Tiempo de generaciÃ³n (10 preguntas):

| Modelo | Tiempo Promedio |
|--------|-----------------|
| Phi-3-mini | ~3 segundos |
| Zephyr-7b | ~5 segundos |
| Mistral-7B | ~6 segundos |
| Mixtral-8x7B | ~15 segundos (si estÃ¡ disponible) |

### Calidad de preguntas:

Todos los modelos recomendados generan preguntas de alta calidad para propÃ³sitos educativos. Las diferencias son mÃ­nimas en la prÃ¡ctica.

---

## âœ… ConclusiÃ³n

**Usa Zephyr-7b-beta** (configuraciÃ³n actual) - Es el mejor balance de:
- âœ… Disponibilidad garantizada
- âœ… Velocidad excelente
- âœ… Calidad muy alta
- âœ… 100% gratis
- âœ… Confiable

**Solo cambia si:**
- Necesitas mÃ¡xima velocidad â†’ Phi-3-mini
- Mixtral funciona consistentemente para ti â†’ Mixtral-8x7B
- Prefieres la familia Mistral â†’ Mistral-7B

---

**Fecha:** 2025-11-18
**VersiÃ³n:** 1.0
